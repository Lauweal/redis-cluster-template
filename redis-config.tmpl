################################## NETWORK #####################################

# 绑定 IP
bind 0.0.0.0

#开启protected-mode保护模式，需配置bind ip或者设置访问密码
#关闭protected-mode模式，此时外部网络可以直接访问
protected-mode no

# 开放端口
port 6379

# tcp 未连接队列数量配置，要注意主进程是否有慢查询，如果出现慢查询
# 这里就会积压，超过这个数量之后就会产生队列溢出，抛弃连接
# 不要大于系统的 /proc/sys/net/core/somaxconn 配置，可以设置成 2048 ，和系统的 somaxconn 一起改
tcp-backlog 511

# 使用 unix socket 形式连接
# unixsocket /run/redis.sock
# unixsocketperm 700

# 客户端空闲多久后关闭连接
timeout 0

# 客户端保持活跃状态的时间，推荐就是 300s 
tcp-keepalive 300

################################# GENERAL #####################################

# 后台运行
daemonize no

# 可以通过upstart和systemd管理Redis守护进程
# 不是我们常见的那个 supervisectl 工具
# upstart 和 systemd 是大部分 Linux 自带的那个
# supervised no      - 无监督互动
# supervised upstart - 通过将Redis置于SIGSTOP模式来启动信号要求在你的upstart作业配置中设置“expect stop”
# supervised systemd - 通过在启动时将READY=1写入$NOTIFY_SOCKET，并定期更新Redis状态来发送信号。
# supervised auto    - 根据UPSTART_JOB或NOTIFY_SOCKET环境变量检测upstart或systemd方法
# supervised auto

supervised no

# 进程id文件存放路径
pidfile /var/run/redis_6379.pid

# 服务端日志输出级别
# 有 debug、verbose、notice、warning 
# debug 输出的内容最多全面，适合测试环境
# notic 和 warning 适合生产环境
loglevel notice

# 配置日志的输出路径
# 如果 daemonize 是 no ，输出到控制台
# 如果 daemonize 是 yes ，输出到指定的路径文件中，如果没配，输出到 /dev/null
logfile "/data/redis-s2.log"

# 库数量
databases 16

# 启动时显示 Redis 的 Logo 不
always-show-logo yes

# Linux 下查看进程名时，是否设置 Redis 的进程名
# 就是我们用 ps 命令查看时的那个名字
set-proc-title yes

# 进程名的模板
proc-title-template "{title} {listen-addr} {server-mode}"

# 设置用于字符串比较操作的本地环境，也会影响Lua脚本的性能。空字符串表示区域设置是从环境变量派生的。
locale-collate ""

################################ REDIS CLUSTER  ###############################

# 普通的 Redis 实例不能成为 Redis 集群的一部分；只有作为集群节点启动的节点可以。为了将 Redis 实例作为集群节点启动，
# 启用集群支持，请取消以下注释。
#
cluster-enabled yes

################################ SNAPSHOTTING  ################################

# RDB 持久化的规则
# save <seconds> <changes> [<seconds> <changes> ...]
# save 3600 1 300 100 60 10000
save 900 1
save 300 10
save 60 10000

# 假如 bgsave 的时候发生问题，默认情况下会禁止写入
# 这个吧，可以帮助发现问题，也就是持久化失败了会很明显的出现无法写入数据的情况
# 但如果你已经有了对于持久化的监控，把它关掉也可以
stop-writes-on-bgsave-error yes

# 是否在持久化时对数据进行 LZF 压缩
rdbcompression yes

# 是否对 RDB 内容进行 CRC64 签名检查
rdbchecksum yes

# 启用或禁用对于 ziplist 和 listpack 的完整整理
# 可以设置 no yes clients 
# 默认值是  clients ，表示仅对客户端连接进行整理，但它会影响集群
# 集群操作时，可以临时设置为 no
sanitize-dump-payload no

# RDB 文件的名称
dbfilename dump.rdb

# 删除同步文件，仅在有 AOF 文件时有效
# 主从复制时，在没有配置 RDB 持久化策略的机器上是否删除复制时使用的 RDB 文件
rdb-del-sync-files no

# 工作目录
# rdb、aof、cluster nodes 文件都会放到这个目录下
dir "/data"

################################# REPLICATION #################################

# 主-副本复制。使用replicaof使一个Redis实例成为另一个Redis服务器的副本
# 关于Redis复制，有几件事需要尽快理解
#
#   +------------------+      +---------------+
#   |      Master      | ---> |    Replica    |
#   | (receive writes) |      |  (exact copy) |
#   +------------------+      +---------------+
#
# 1) Redis复制是异步的，但是你可以配置一个master,
#    如果它看起来没有连接到至少一个给定数量的副本,那
#    么它就会停止接受写操作
# 2) 如果复制链路丢失相对较短的时间，Redis副本可以执行与主服务器的部分重同步。
#    您可能希望根据您的需要将复制积压大小(请参阅本文件的下一部分)配置为合理的值
# 3) 复制是自动的，不需要用户干预。在网络分区之后，
#    副本自动尝试重新连接到主服务器并与它们重新同步
# replicaof <masterip> <masterport>

# 主从配置时认证相关的内容
# 当指定masteruser时，副本将使用新的AUTH形式对其主服务器进行身份验证:AUTH <username> <password>。
# masterauth <master-password>
# masteruser <username>

# 当副本失去与主服务器的连接时，或者当复制仍在进行时，副本可以采取两种不同的方式:
#
# 1) 如果replica-serve-stale-data设置为'yes'(默认值)，副本仍然会回复客户端请求，可能带有过期的数据，或者如果这是第一次同步，数据集可能只是空的。
#
# 2) 如果replica- server -stale-data设置为no，则对所有的数据访问命令，
#    除了INFO、REPLICAOF、AUTH、SHUTDOWN、REPLCONF、ROLE、CONFIG、
#    SUBSCRIBE、UNSUBSCRIBE、PSUBSCRIBE、PUNSUBSCRIBE、PUBLISH、
#    PUBSUB、COMMAND、POST、HOST和LATENCY等命令外，副本将回复错误
#    “MASTERDOWN Link with MASTER is down and replica- server -stale-data is set to 'no”。
replica-serve-stale-data yes

# 配置从库是否是只读的，换成 no 的话就也可以写入数据了
replica-read-only yes

# 复制的同步策略，使用磁盘还是socket
# 新的副本和重新连接的副本不能继续复制过程，只是接收差异，需要执行所谓的“完全同步”。RDB文件从主数据库传输到副本。
# 这种传播可以通过两种方式发生:
# 1) Disk-backed: Redis master创建一个新进程，将RDB文件写入磁盘。随后，该文件由父进程以增量方式传输到副本。
# 2) Diskless: Redis master创建了一个新进程，直接将RDB文件写入副本套接字，而不涉及磁盘。
repl-diskless-sync no

# 当使用无盘复制的时候，可以配置等待时间
# 一般主库会等待一会再向从库发送数据
repl-diskless-sync-delay 5

# 当使用延迟启用无磁盘复制时，如果连接的副本达到预期的最大数量，则可以在达到最大延迟之前启动复制。
# 默认值为0表示没有定义最大值，Redis将等待完整的延迟。
repl-diskless-sync-max-replicas 0

# -----------------------------------------------------------------------------
# 无盘加载
# 一般情况下，socket 会比文件传输快，但也有可能传送时有新的数据
# 这里的配置如果是 disabled ，就是不使用无盘复制，先将文件保存到磁盘再加载
# "disabled"    - 不要使用无磁盘加载(首先将rdb文件存储到磁盘上)
# "swapdb"      - 在直接从套接字解析数据时，将当前db内容保存在RAM中。
#                 这种模式下的副本可以在复制过程中继续服务当前数据集，
#                 除非它们不能识别出主数据集具有来自相同复制历史的数
#                 据集。注意，这需要足够的内存，如果没有足够的内存，
#                 就有可能导致OOM死亡。
# "on-empty-db" - 仅在当前数据集为空时使用无磁盘加载。这样更安全，避
#                 免了在复制过程中同时加载旧数据集和新数据集。
repl-diskless-load disabled

# 同步之后是否禁用主库上的 TCP_NODELAY 
# 使用 yes 会使用较少的包向从库发送数据，但会增加延迟和带宽
repl-disable-tcp-nodelay no

# 复制副本的优先级 优先级高的副本在哨兵选举时的得分会更高
replica-priority 100

# 防止主从复制不一致
propagation-error-behavior panic

# -----------------------------------------------------------------------------
# 默认情况下，Redis Sentinel 在其报告中包括所有副本。一个副本可以从 Redis Sentinel 的公告
# 中排除。一个未公布的副本将被 'sentinel replicas <master>' 命令忽略，并且不会暴露给 Redis 
# Sentinel 的客户端。
# 这个选项并不改变副本优先级的行为。即使把 replica-announced 设置为'no'，副本也可以被提升为
# master。为了防止这种行为，请将 replica-priority 设置为 0。
#
# replica-announced yes

# It is possible for a master to stop accepting writes if there are less than
# N replicas connected, having a lag less or equal than M seconds.
#
# The N replicas need to be in "online" state.
#
# The lag in seconds, that must be <= the specified value, is calculated from
# the last ping received from the replica, that is usually sent every second.
#
# This option does not GUARANTEE that N replicas will accept the write, but
# will limit the window of exposure for lost writes in case not enough replicas
# are available, to the specified number of seconds.
#
# For example to require at least 3 replicas with a lag <= 10 seconds use:
#
# min-replicas-to-write 3
# min-replicas-max-lag 10
#
# Setting one or the other to 0 disables the feature.
#
# By default min-replicas-to-write is set to 0 (feature disabled) and
# min-replicas-max-lag is set to 10.

# A Redis master is able to list the address and port of the attached
# replicas in different ways. For example the "INFO replication" section
# offers this information, which is used, among other tools, by
# Redis Sentinel in order to discover replica instances.
# Another place where this info is available is in the output of the
# "ROLE" command of a master.
#
# The listed IP address and port normally reported by a replica is
# obtained in the following way:
#
#   IP: The address is auto detected by checking the peer address
#   of the socket used by the replica to connect with the master.
#
#   Port: The port is communicated by the replica during the replication
#   handshake, and is normally the port that the replica is using to
#   listen for connections.
#
# However when port forwarding or Network Address Translation (NAT) is
# used, the replica may actually be reachable via different IP and port
# pairs. The following two options can be used by a replica in order to
# report to its master a specific set of IP and port, so that both INFO
# and ROLE will report those values.
#
# There is no need to use both the options if you need to override just
# the port or the IP address.
#
replica-announce-ip 127.0.0.1
replica-announce-port 6379

################################## SECURITY ###################################

# ACL 日志长度
acllog-max-len 128

# 使用单独的 acl 文件保存 acl 用户信息
# aclfile /etc/redis/users.acl

# 全局密码配置
# requirepass foobared

# 禁用KEYS命令
# 一方面 KEYS * 命令可以列出所有的键，会影响数据安全
# 另一方面 KEYS 命令会阻塞数据库，在数据库中存储了大量数据时，该命令会消耗很长时间
# 期间对Redis的访问也会被阻塞，而当锁释放的一瞬间，大量请求涌入Redis，会造成Redis直接崩溃
rename-command KEYS ""

################################### CLIENTS ####################################

# 设置同时连接的最大客户端数
# maxclients 10000

############################## MEMORY MANAGEMENT ################################

# 设置最大内存可用数量
# maxmemory <bytes>

# 内存淘汰策略
# 当内存容量达到 maxmemory 设置的值之后，如何腾出新的内存空间
# volatile-lru：从已设置过期时间的key集中,挑选最近最少使用的数据淘汰。
# volatile-ttl：从已设置过期时间的key集中,挑选将要过期的数据淘汰。
# volatile-random：从已设置过期时间的key集中,任意选择数据淘汰。
# volatile-lfu：从已设置过期时间的key集中,挑选使用频率最低的数据淘汰。
# allkeys-lru：从key集中,挑选最近最少使用的数据淘汰
# allkeys-lfu：从key集中,挑选使用频率最低的数据淘汰。
# allkeys-random：从key集中,（server.db[i].dict）任意选择数据淘汰
# noeviction：不进行移除。针对写操作，只是返回错误信息
maxmemory-policy noeviction

# 大量淘汰内存时阻塞客户端的时间
# maxmemory-eviction-tenacity 10

# 从库是否忽略淘汰内存限制
# replica-ignore-maxmemory yes

# 清理过期键时的CPU占比消耗
# 1-10 越大占用CPU资源越多
# active-expire-effort 1

############################# LAZY FREEING ####################################
# 针对有配置淘汰策略的情况下，发生内存淘汰时，是否使用 LazyFree
lazyfree-lazy-eviction no

# 针对过期的Key，开始删除清理时，是否使用 LazyFree
lazyfree-lazy-expire no

# 有些指令在操作时，如 rename ，会隐性地带一个 del 操作，是否使用 LazyFree
lazyfree-lazy-server-del no

# 对于从库，在刚启动，没有同步主库数据前，会先 FLUSHALL ，这时是否使用 LazyFree
replica-lazy-flush no

# 修改 del 的默认行为，让它变得和 unlink 一样
lazyfree-lazy-user-del no

# FLUSHDB, FLUSHALL, 和 SCRIPT FLUSH ，本来是支持用一个参数 [SYNC|ASYNC] 来指定同步还是异步操作的
# 开启这个之后，就让它们都变成异步的，不需要加参数了
lazyfree-lazy-user-flush no

################################ THREADED I/O #################################

# 线程数量
io-threads 4

# 开启 IO 多线程功能，默认是关闭的
io-threads-do-reads yes

############################ KERNEL OOM CONTROL ##############################

# 在 Linux 中，如果内存不足会启动 OOM Killer 去杀进程
# 开启这个功能将可以让 Redis 控制 oom_score_adj 函数的值
# 在主进程被 kill 之前，根据数据库的情况去 kill 子进程
# 可以配置 no、yes、absolute、relative 等值
oom-score-adj no

# 当 oom-score-adj 被开启之后，这里就是它的参考值
oom-score-adj-values 0 200 800


#################### KERNEL transparent hugepage CONTROL ######################

## 内存优化 是否启用 thp 机制
disable-thp yes

############################## APPEND ONLY MODE ###############################

## redis持久化　　默认是no
appendonly yes
appendfilename "appendonly.aof"
appenddirname "appendonlydir"
appendfsync everysec
no-appendfsync-on-rewrite no
auto-aof-rewrite-percentage 100
auto-aof-rewrite-min-size 64mb
aof-load-truncated yes
aof-timestamp-enabled no

################ NON-DETERMINISTIC LONG BLOCKING COMMANDS #####################

# 一个Lua脚本最长的执行时间，单位为毫秒，如果为0或负数表示无限执行时间，默认为5000
lua-time-limit 5000
busy-reply-threshold 5000

################################## SLOW LOG ###################################

# 决定要对执行时间大于多少微秒(microsecond，1秒 = 1,000,000 微秒)的查询进行记录
slowlog-log-slower-than 10000

# 它决定 slow log 最多能保存多少条日志， slow log 本身是一个 FIFO 队列，当队列大
# 小超过 slowlog-max-len 时，最旧的一条日志将被删除，而最新的一条日志加入到 slow log ，以此类推。
slowlog-max-len 128

################################ LATENCY MONITOR ##############################

# 能够采样不同的执行路径来知道redis阻塞在哪里。这使得调试各种延时问题变得简单，
# 设置一个毫秒单位的延时阈值来开启延时监控。
latency-monitor-threshold 0

############################# EVENT NOTIFICATION ##############################

# Redis 可以通知 Pub/Sub 客户端在钥匙空间中发生的事件。这个功能的文档在 https://redis.io/topics/notifications
#
# 例如，如果钥匙空间事件通知被启用，并且客户端对存储在数据库 0 中的钥匙 "foo" 执行了 DEL 操作，两个消息将通过Pub/Sub发布：
#
# PUBLISH __keyspace@0__:foo del
# PUBLISH __keyevent@0__:del foo
#
# 可以在一组类中选择 Redis 将通知的事件。每个类都由一个字符来标识。
#
# K 关键空间事件，用__keyspace@<db>__前缀发布。
# E 关键事件，用__keyevent@<db>__前缀发布。
# g 通用命令（非特定类型），如DEL, EXPIRE, RENAME, ...
# $ 字符串命令
# l 列表命令
# s 设置命令
# h 哈希命令
# z 排序的集合命令
# x 过期事件（每次密钥过期时产生的事件）。
# e 驱逐事件（当一把钥匙被驱逐到最大内存时产生的事件）。
# n 新钥匙事件（注意：不包括在'A'类中）。
# t 流命令
# d 模块键类型事件
# m 钥匙丢失事件（注意：不包括在'A'类中）
# A g$lshzxetd的别名，因此 "AKE "字符串表示所有的事件（除了钥匙丢失事件，由于其独特的性质，不包括在 "A "中）。
#
# "notify-keyspace-events" 的参数是一个由零或多个字符组成的字符串。空字符串意味着通知被禁用。
#
# 示例：要启用列表和通用事件，从事件名称的角度，使用：
#
#  notify-keyspace-events Elg
#
# 例子2：获取订阅通道的过期密钥流
# name __keyevent@0__:expired use:
#
# notify-keyspace-events Ex
#
# 默认情况下，所有的通知都是禁用的，因为大多数用户不需要这个功能，而且这个功能有一些开销。注意，如果你没有指定 K 或 E 中
# 的至少一个，就不会有事件被传递。
notify-keyspace-events ""

############################### ADVANCED CONFIG ###############################

# 当哈希值有少量的条目，并且最大的条目不超过一个给定的阈值时，哈希值就会使用一个内存效率高的数据结构进行编码。
# 这些阈值可以通过以下指令来配置。
hash-max-listpack-entries 512
hash-max-listpack-value 64

# 列表也以一种特殊的方式进行编码，以节省大量的空间。每个内部列表节点允许的条目数可以指定为一个固定的最大尺寸或最大元素数。
# 对于一个固定的最大尺寸，使用-5到-1，意思是：
# -5: 最大尺寸: 64 Kb   <-- 不建议用于正常工作负载
# -4：最大尺寸：32 Kb   <-- 不建议使用
# -3：最大尺寸：16 Kb   <-- 可能不建议使用
# -2：最大尺寸：8 Kb    <-- 良好
# -1: 最大尺寸：4 Kb    <-- 良好
# 正数意味着每一个列表节点最多存储_个元素的数量。性能最高的选项通常是-2（8 Kb大小）或-1（4 Kb大小），但如果你的使用情况特殊，
# 可以根据需要调整设置。
list-max-listpack-size -2

# 列表也可以被压缩。压缩深度是指从列表的 *each* 边开始 *exclude* 压缩的快速列表 ziplist 节点的数量。 列表的头部和尾部
# 总是未被压缩的，以便进行快速推/拉操作。 设置如下：
# 0: 禁用所有的列表压缩。
# 1：深度 1 意味着 "在列表的 1 个节点之后才开始压缩，从头部或尾部开始"。
#   因此：[head]->node->node->...->节点->[tail]
#    [head], [tail]将永远是未压缩的；内部节点将被压缩
# 2: [head]->[next]->node->node->...->node->[prev]->[tail] 。
#   2 在这里的意思是：不要压缩 head 或 head->next 或 tail->prev 或 tail，而是压缩它们之间的所有节点。
# 3: [head]->[next]->[next]->node->node->...->node->[prev]->[prev]->[tail] 等等。
list-compress-depth 0

# 集合只在一种情况下有特殊的编码：当一个集合只是由刚好是 64 位有符号整数范围内的 radix 10 的字符串组成时。
# 下面的配置设置设置了集合的大小限制，以便使用这种特殊的节省内存的编码。
set-max-intset-entries 512
set-max-listpack-entries 128
set-max-listpack-value 64

# 与哈希值和列表类似，排序集也被特别编码，以节省大量空间。这种编码只有在排序集的长度和元素低于以下限制时才会使用。
zset-max-listpack-entries 128
zset-max-listpack-value 64
hll-sparse-max-bytes 3000
stream-node-max-bytes 4096
stream-node-max-entries 100
activerehashing yes
client-output-buffer-limit normal 0 0 0
client-output-buffer-limit replica 256mb 64mb 60
client-output-buffer-limit pubsub 32mb 8mb 60
hz 10
dynamic-hz yes
aof-rewrite-incremental-fsync yes
rdb-save-incremental-fsync yes

########################### ACTIVE DEFRAGMENTATION #######################
jemalloc-bg-thread yes